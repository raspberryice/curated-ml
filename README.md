# Curated-ML.

A curation of ML blogs, courses and papers. Welcome to contribute!

## Blogs 


- [Off the Convex Path](https://www.offconvex.org/) Research blog from Sanjeev Arora's group on optimization in deep learning. 
( They have some very interesting work on understanding the theoretical properties of word embeddings. )

- [BAIR](https://bair.berkeley.edu/blog/) Research blog from Berkeley Artificial Intelligence Research. They specialize in deep reinforcement learning but also cover other topics. 
- [The Gradient](https://thegradient.pub/)  A digital magazine on AI founded by people from Stanford Artificial Intelligence Laboratory(SAIL). They cover a wide range of topics in a more accessible manner (not only talking to researchers) Topics include the impact of AI and reflections on the community.
- [Distill Pub](https://distill.pub/) An online journal that focuses on interpretability. They have great visualizations! 
- [Lil's Log](https://lilianweng.github.io/lil-log/) Survey style blogs on reinforcement learning, generative models, nlp. Great place to learn about a topic.
- [Google AI blog](https://ai.googleblog.com/)
- [OpenAI](https://openai.com/blog/) Reinforcement learning & large language models (GPT).
- [DeepMind](https://deepmind.com/blog)
- [FAIR](https://ai.facebook.com/blog/) Facebook AI Blog.
- [NLP Highlights](https://soundcloud.com/nlp-highlights) Although not exact a blog, this is an excellent podcast hosted by Matt Gardner and Waleed Ammar from Allen Institute for Artificial Intelligence.
- [Sebastian Ruder's blog](http://ruder.io/) Sebastian also distributes a monthly newsletter called "NLP News" that can be delivered right to your mailbox! 
- [The Morning Paper](https://blog.acolyer.org/) Adrian Colyer covers one paper each day. Not limited to ML.
- [Gradient Science](https://gradientscience.org/) Research blog from the MadryLab at MIT. Focuses on adversarial machine learning & security.
- [I'm a bandit](https://blogs.princeton.edu/imabandit/) Blog by Sebastien Bubeck on optimization, probability and statistics.
- [Christopher Olah](https://colah.github.io/) Includes one very classic blog on LSTMs. Chris now writes more for Distill.
- [AI2](https://medium.com/ai2-blog) 
- [Stanford DAWN](https://dawn.cs.stanford.edu/blog/) Topics include how to train with weak supervision (Snorkel project) and how to speed up training (DAWNBenchmark project).
- [Andrej Karpathy](http://karpathy.github.io/) Time and time again I come back to his advice on training neural networks.
- [HuggingFace](https://huggingface.co/)

